# annotated-transformer-fr
The anotated transformer translated in french (fr to en)

Cette traduction est

- Basée sur une traduction "The annotated transformer" de Austin Huang et al. : http://nlp.seas.harvard.edu/annotated-transformer/

- Basée sur "The annotated transformer" de Sasha Alexander Rush et al. : https://nlp.seas.harvard.edu/2018/04/03/attention.html

- Basée sur "Attention is all you Need" de Hashish Vaswani et al. : https://arxiv.org/abs/1706.03762

https://doi.org/10.48550/arxiv.1706.03762, doi = {10.48550/ARXIV.1706.03762}, url = {https://arxiv.org/abs/1706.03762%7D, author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia}, keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}, title = {Attention Is All You Need}, publisher = {arXiv}, year = {2017}, copyright = {arXiv.org perpetual, non-exclusive license}

Attention is All You Need

v2022: Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak, and Stella Biderman.

[Original](https://nlp.seas.harvard.edu/2018/04/03/attention.html): Sasha Rush
